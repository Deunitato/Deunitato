---
layout: post
title: 'CS2106: Lecture 3 - Process Scheduling'
date: '2020-02-04T19:48:00.000-08:00'
author: Charlotte Deunitato
tags: 
modified_time: '2020-02-12T23:36:04.692-08:00'
blogger_id: tag:blogger.com,1999:blog-4520250687931855860.post-5870890388127528501
blogger_orig_url: https://nusmods.blogspot.com/2020/02/cs2106-lecture-4-process-scheduling.html
---

<h2>Questions from Archi</h2><div>- In a multi core archi, does each core have its own scheduler</div><div>A: There is one for each core. Lab2 will build it.</div><div><br /></div><div>- If we use a code that does not import any lib, is path D still use</div><div>e.g int main() {return 0;}</div><div>(Ref to diagram)</div><div><br /></div><div>A: Not all syscall have to been in the code so setting up will still use path D.</div><div>Some implied lib calls happen in intitalise.</div><div><br /></div><div>- Conceptually there would be multiple block queues for the different event right</div><div>A: For diff event types some structures might be more suitable than others</div><div><br /></div><div><i>We can have multiple queues for different things</i></div><div><i><br /></i></div><h2>Concurrent execution</h2><div>- Virtual or physical parellism</div><div>Its an illusion of paralleism even thou we have only one single core</div><div><br /></div><div>If there is one core, there is only one truly running process but they can take turns. While one is waiting, the other is running.</div><div>This is the concurrency.</div><div><br /></div><div>Physical:<br />The concurrency is happening in hardware. (Parallelism in hardware)</div><div>- Multi core&nbsp;</div><div>- Multi context in hardware</div><div><br /></div><div>Scheduling policies are not really related to parallelism</div><div><br /></div><div><i><u>Insert slide 5</u></i></div><div><i><u><br /></u></i></div><div><i>This is an example of concurrent execution on a single core.</i></div><div><i>Time Slicing</i></div><div><i>There is performance&nbsp;impact but there is no correctness problem</i></div><div><i>-&gt; This is make sure by the OS</i></div><div><i>-&gt; The OS have a short period of time to save the context and to restore (take a ss) before the scheduler pick another process</i></div><div><i>- The os then pull out the context of the other process</i></div><div><i>- This is called context switch: Switching the context of one process and saving the other</i></div><div><i><br /></i></div><h3>Context Switch</h3><div>1. Process A decided to switch</div><div>2. The OS save the state into PCB</div><div>3. Meanwhile, the scheduler is invoke to select another process</div><div>4. The process p1 continues and when it is done (interrupt)</div><div>5. It saves its context and reload the previous Process A</div><div><br /></div><div><i>Do we need to keep the PCB structure updated at all time</i></div><div><i>-&gt; no</i></div><div><i>It is a hassle to update everything, register is involved</i></div><div><i>We only save stuff into memory when something (interrupt) happens</i></div><div><i><br /></i></div><h3>Multitasking OS</h3><div>Each process queue for OS.</div><div><br /></div><div>One CPU: Time slice</div><div>Multi: Scheduler decides which Core for which processes</div><div><br /></div><h3>Scheduling</h3><div>It is a part of the OS that makes the scheduling decisions</div><div>The scheduler will select and pick a few processes to run on the CPU.</div><div>How to select?</div><div>Multiple ways to allocate:</div><div>Influence by process environment -&gt; Scheduling algo</div><div><br /></div><div><b>Process Behavior</b></div><div><br /></div><div>CPU:&nbsp;</div><div>- Computation</div><div>- Number crunching</div><div><br /></div><div>IO:<br />- Request and receiving service from io devices</div><div>- IO bound process spend majority of its time here.</div><div><br /></div><div>IO usually waits slower than processors.</div><div>The prog that usually change between the two modes, the scheduler must know what kind of process it is (IO/CPU boound) to make different policies for each of the processes</div><div><br /></div><h3>Processing environment</h3><div><b>Batch processing</b></div><div>Just submit the job to. No interaction required and no need to be responsive</div><div>This job is very easy to schedule</div><div><br /></div><div><b>Interactive</b></div><div><b>- </b>With active user interacting with system</div><div>- Must be responsive, consistent in response time</div><div>- e.g Microsoft word (when we type something,we do not want to wait for a few seconds before seeing the word)<br />It does not do anything until you press something. (IO intensive)<br />While it is waiting, it is block. [There are some systems that are interactive but not IO intensive]<br /><br /></div><div><br /></div><div><b>Real time processing</b></div><div>Have a deadline</div><div>Task are usually periodic</div><div><br /></div><div>Task in RTP Is usually superior.</div><div><br /></div><h3>Criterias for algo</h3><div>- Fair</div><div>Must have a shared time for CPU</div><div>No starvation</div><div><br /></div><div>- Balance</div><div>All parts of the computing system should be utilized</div><div>We do not want to have a bottleneck in the system</div><div><br /></div><h3>When to perform scheduling</h3><div>- Non preemptive</div><div>Scheduler cannot decide when to kick you out of the CPU until you give up volunterrily</div><div>(Usual for batch systems)<br /><br /></div><div>- Preemptive</div><div>Usually periodic</div><div><br /></div><div><i>When do we call the scheduler?<br />When a process is finish/block, another process is to be picked.</i></div><div><br /></div><div>1. Scheduler is trigger (OS take over)</div><div>2. If context switch:</div><div>Context of running is save and place into queue (ready or block)</div><div>3. Scheudler use its algo to pick process p</div><div>4. Set up context for p</div><div>5. Run process p</div><div><br /></div><h2>Batch Processing</h2><div>Criteria:</div><div>- Throughput: Number of tasks finish per unit line</div><div>- Turnaround time: Total wall clock time taken, related to waiting time for CPU</div><div>- CPU utilization: Percentage of time when CPU is working on task</div><div><br /></div><h3>FCFS</h3><div>- The first process in the queue is served first</div><div>- No starvation (every process is guaranteed time and the queue is always decreasing)</div><div>-&nbsp; NO priority</div><div><br /></div><div>Problems:</div><div>- If there is a long task infront, the waiting task behind will have to wait time(A) to finish.</div><div>It will be better if we reorder the time to shortest to longest. (But this might cause a problem)</div><div><br /></div><h3>SJF</h3><div>- Select the task with the shortest total CPU time</div><div><br /></div><div>Problem:</div><div>- We do not know how long it takes to finish</div><div>- We can use Exponential Avg&nbsp;</div><div>Predn+1 = aActualn + (1- a) predn</div><div><br /></div><div>Actualn = the most recent CPU time consumed</div><div>Predictedn = the past history of CPU time consumed</div><div>a = Weight placed on recent event or past history</div><div>Predictedn+1 = latest prediction</div><div><br /></div><div><i>This equation is use to predict the CPU time taken for the incoming task</i></div><div>The scheduler will use the results of this equation to scheduler the job accordingly to SJF.</div><div><br /></div><div><br /></div><div><h2>Last week from archi</h2></div><div>1. Copy one write approach to forks which only copies memory when necessary, why is there a need for clone which only copy specific.</div><div><br /></div><div>Fork is a lib call while clone is the underlying sys call.</div><div>Copy on write is a perf optimization for data that is shared.</div><div>Do we want to share everything with the child?</div><div>Clone have a better flexibility to allow us to select which part of the memory to share with the child.</div><div>IT does not matter if its copy on write</div><div><br /></div><div>2. How does child process know if its should read from own pcb or parents using the copy on write optimization?</div><div><br /></div><div>PCB is part of the OS context of a process. The process do not know about it but the OS does. This is abstraction.</div><div><br /></div><div>3. In what case we use wait and sleep</div><div>wait -&gt; Process to&nbsp; finish&nbsp;</div><div>Sleep -&gt; wait for a set amt of time</div><div><br /></div><div>Q4. Do we create a new process ID for the child process when we fork or do we defer that to when there is a write (according to the copy then write)</div><div><br /></div><div>Fork returns different values to child and parent</div><div>To parent = id of child</div><div>To child = 0</div><div>We always create the process ID first</div><div><br /></div><div>Q5. Is the PCB stored in memory? And does it contain or does it point to the heap stack data and text.</div><div><br /></div><div>The PCB are stored in OS memory and its only accessible to kernel.</div><div>It is stored in kernel memory which is smaller than memory.</div><div>So it cannot store all the actual data but contains the information required to access the memory.</div><div>(Does not have to be pointers)</div><div><br /></div><div>Q6 When do we get segmentation fault?</div><div>When the program generation an address that does not belong to the program.</div><div><br /></div><div>Q7 When the process/program encounters a page fault (accessing mem that has not been allocated), Does the process become blocked instead of terminated since it can restart from that particular instruction?</div><div><br /></div><div>This is a different type of fault. It is not segmentation (Memory managment topic in week 9)</div><div><br /></div><div>Q8 Some C string literals are read onlu</div><div>char * S = "hello"</div><div>C treats it as immutable</div><div><br /></div><div><h3>SRT</h3><div>Shortest time remaining : Select job with the shortest remaining time or the expectation</div><div><br /></div><div>How is this different with SJF?<br />- The order of process is different</div><div>- When a new process enter, it will be different</div><div>- This is preemptive variant of SJF<br /></div><div>Provides good service for short job even when it arrives late.</div><div><br /></div><div><br /></div><h2>Interactive environment</h2><div>Response time: Time between request and response by system</div><div><br /></div><div>Predictability: Variation in response time, less variation -&gt; More predictable</div><div><br /></div><div>Preemptive scheduling algo are use to ensure good response time</div><div>-&gt; Scheduler needs to run preiodically</div><div><i>keep track of time and to ensure each process have its own set of time to run</i></div><div><i><br /></i></div><div>How do we make sure the scheduler takes over the CPU periodically?</div><div>-&gt; timer interrupt = base on hardware clock</div><div><br /></div><h3>Terminology: Timer and time quantum</h3><div><b>Interval of timer interrupt</b></div><div>Os scheduler is triggered every timer interrupt</div><div>Typical values (1ms to 10ms)</div><div><br /></div><div><b>Time quantum</b></div><div>Execution duration given to a process</div><div>Could be constant or variable among the process</div><div>Must be multiples of interval of timer interrupt</div><div>Large range of values (5ms to 100ns)</div><div><br /></div><h3>Scheduling Algo:</h3></div><div>1. Round Robin</div><div>Pick the first task from queue and run till</div><div>- a fixed time slice</div><div>- Task gives up</div><div>- Task blocks</div><div><br /></div><div>Notes:</div><div>It is preemptive of FCFS</div><div>Guarantee the time before the task to get CPU (n-1)q</div><div><br /></div><div>Choice of time quantum duration isimport:</div><div>big: Better CPU util but more waiting time&nbsp;</div><div>samll: Bigger CPU util but shorter waiting time&nbsp; [More context switch]</div><div><br /></div><div><br /></div><div><br /></div><div><br /></div><div><br /></div><div><br /></div><div>2. Priority based</div><div>Some process are&nbsp; more important than others</div><div>Assign a priority value to asll task</div><div><br /></div><div>There is preemptive and non premptive</div><div><br /></div><div>Problem:</div><div>Low priority may starve.</div><div>High priority process keep hogging the CPU</div><div><br /></div><div>Worse in pre-emptive:</div><div>- Preemptive ensure that each job get fix amount of time quantum so if a low pirority job waited so long just for a short amount of time, the prob will become worse</div><div><br /></div><div>Sol:</div><div>Decrease priority each time it gets a chance to run</div><div>However, it is difficult to control the exact amount of CPU time given to a process using priority</div><div><h4>Priority inversion</h4><div>If a process use a resource and was lock due to it not finishing it and another high priority task come in needing the same resource.</div><div><br /></div><div>The next process (not the high priority one) gets to execute because of the first process not finishing it yet/</div><div><br /></div><div><br /></div><div><br /></div><div><br /></div><div><br /></div><div><br /></div></div><div>3. Multi level feedback queue</div><div>Determine what time of process it is and classify it.</div><div><br /></div><div>Adaptive.: Learn the process behavior automatically</div><div>Seeks to minimize:</div><div>- RT for interactive and IO bound process</div><div>- Turnaround time</div><div><br /></div><div>For different priority, there are different algo running.</div><div>If a job utilize its time slice, the priority is reduce</div><div><br /></div><div><i>There are different queue for differenet priority processes.</i></div><div><i><br /></i></div><div><br /></div><div><br /></div><div>4. Lottery scheduling</div><div><br /></div><div>Give out lottery tickets to processes for various system resource.</div><div>When scheduling decision is needed:</div><div>Lottery ticket is chosen randomly among eligible tickets</div><div>Winner is granted resource</div><div><br /></div><div><i>For each TQ, each TQ have a lottery tickets. We are bias towards some proceess due to the priority. (Give more tickets to that process)</i></div><div><i><br /></i></div><div>Responsive:<br />A new created process can participate in the next lottery/</div><div>Provides a decent level of control:<br />A process can be give Y lottery tickets, it can distribute to its child process.</div><div><br /></div><div><br /></div><div><br /></div><div><br /></div><div><i><br /></i></div>